#!/usr/bin/env python3
"""
Test fetching all pages from task-search endpoint
"""

import requests
import json
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_all_pages_fetch():
    """Test fetching all pages from task-search"""
    try:
        # Your provided access token
        access_token = "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6Ik4wRTNNa1l3TlVGQk1EQkZOREEzTVRVMFEwSTJSRGxCUkRFelFqa3pOVFl4TWpZMlJUUkNNUSJ9.eyJsb2N1cy1hdHRyaWJ1dGVzIjp7ImN1c3RvbVZhbHVlcyI6eyJkYXRhQ2xpZW50SWQiOiJpbGxhLWZyb250ZG9vciJ9LCJwZXJzb25uZWxJZCI6ImlsbGEtZnJvbnRkb29yL3BlcnNvbm5lbC9BbWluIn0sImlzcyI6Imh0dHBzOi8vYWNjb3VudHMubG9jdXMtZGFzaGJvYXJkLmNvbS8iLCJzdWIiOiJhdXRoMHxwZXJzb25uZWxzfGlsbGEtZnJvbnRkb29yL3BlcnNvbm5lbC9BbWluIiwiYXVkIjpbImh0dHBzOi8vYXdzLXVzLWVhc3QtMS5sb2N1cy1hcGkuY29tIiwiaHR0cHM6Ly9sb2N1cy1hd3MtdXMtZWFzdC0xLmF1dGgwLmNvbS91c2VyaW5mbyJdLCJpYXQiOjE3NTg4MzA2NTIsImV4cCI6MTc1ODg3Mzg1Miwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBlbWFpbCIsImF6cCI6IkNMMm1sYnJMZ2Z3N2RTOGFkcDV4MzE5aXVQT0pySlZlIn0.jNIJoulmMmvfbS8R0_1NvF-kXlzmWtCBxbCJTAXPU0HE3b7q7Qwr5digjW58L5a3Ny8rNjNam3YaIvzhcV-itmcCmbI1LuuCBwPjNEMJwBMAVI6asiqGm0l2buX1k5roJsh7nK3b0HpY3ZTZqxurWO8CiO6dzNcYrPqUvYYCkBOkx_VSnaSD9ABQ0PZYb28wAB-EY2puB3itNAuB3PTAbjsI90fS7A55nJ1VcmFZFx9-xsQBVtusDAQyr4tICCRyzl-0FKeNl_e0_ytlboIrHIbe-76eHVgxSJdoxwYlLXSVEOjBwPbB3oRbfELEsoB7l3cFdbY34eX_Iskh9A3hjg"

        url = "https://dash.locus-api.com/v1/client/illa-frontdoor/task-search?include=FLEET%2CLOCATION%2CCROSSDOCK&countsOnly=false&pageSize=50"

        headers = {
            'accept': 'application/json',
            'accept-language': 'en-US,en;q=0.9',
            'authorization': f'Bearer {access_token}',
            'content-type': 'application/json',
            'l-custom-user-agent': 'cerebro',
            'origin': 'https://illa-frontdoor.locus-dashboard.com',
            'priority': 'u=1, i',
            'referer': 'https://illa-frontdoor.locus-dashboard.com/',
            'sec-ch-ua': '"Not)A;Brand";v="8", "Chromium";v="138", "Google Chrome";v="138"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Linux"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'cross-site',
            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36'
        }

        def get_page(page_num):
            payload = {
                "filters": [
                    {
                        "name": "teamId.teamId",
                        "operation": "EQUALS",
                        "value": None,
                        "values": ["101"],
                        "allowEmptyOrNull": False,
                        "caseSensitive": False
                    },
                    {
                        "name": "date",
                        "operation": "EQUALS",
                        "value": "2025-09-25",
                        "values": [],
                        "allowEmptyOrNull": False,
                        "caseSensitive": False
                    }
                ],
                "complexFilters": None,
                "sortingInfo": None,
                "size": 50,
                "page": page_num,
                "skipPaginationInfo": False
            }

            logger.info(f"ğŸ“„ Fetching page {page_num}...")
            response = requests.post(url, headers=headers, json=payload)

            if response.status_code == 200:
                data = response.json()
                tasks = data.get('tasks', [])
                pagination_info = data.get('paginationInfo', {})

                logger.info(f"   âœ… Page {page_num}: {len(tasks)} tasks")
                logger.info(f"   ğŸ“Š Pagination: {pagination_info}")

                return data
            else:
                logger.error(f"   âŒ Page {page_num} failed: {response.status_code}")
                return None

        logger.info("ğŸ” Testing complete pagination flow...")

        # Step 1: Get first page to determine total pages
        logger.info("ğŸ“„ Fetching first page to get pagination info...")
        first_page = get_page(1)

        if not first_page:
            logger.error("âŒ Failed to fetch first page")
            return False

        pagination_info = first_page.get('paginationInfo', {})
        total = pagination_info.get('total', 0)
        number_of_pages = pagination_info.get('numberOfPages', 1)

        logger.info(f"ğŸ“Š Total tasks: {total}")
        logger.info(f"ğŸ“Š Number of pages: {number_of_pages}")

        all_tasks = first_page.get('tasks', [])
        logger.info(f"ğŸ“¦ First page: {len(all_tasks)} tasks")

        # Step 2: Fetch remaining pages
        if number_of_pages > 1:
            logger.info(f"ğŸ“„ Fetching remaining {number_of_pages - 1} pages...")

            for page_num in range(2, number_of_pages + 1):
                page_data = get_page(page_num)

                if page_data:
                    page_tasks = page_data.get('tasks', [])
                    all_tasks.extend(page_tasks)
                    logger.info(f"   ğŸ“¦ Page {page_num}: Added {len(page_tasks)} tasks (Total: {len(all_tasks)})")
                else:
                    logger.warning(f"   âš ï¸ Failed to fetch page {page_num}")

        logger.info(f"\nâœ… Complete fetch results:")
        logger.info(f"   ğŸ“Š Total tasks fetched: {len(all_tasks)}")
        logger.info(f"   ğŸ“Š Expected total: {total}")
        logger.info(f"   ğŸ“Š Pages fetched: {number_of_pages}")

        # Test some task data
        if all_tasks:
            # Check for different statuses
            status_counts = {}
            cancelled_with_reasons = 0

            for task in all_tasks:
                status = task.get('effectiveStatus', 'UNKNOWN')
                status_counts[status] = status_counts.get(status, 0) + 1

                # Check cancellation reasons
                if status == 'CANCELLED':
                    customer_visit = task.get('customerVisit', {})
                    checklists = customer_visit.get('checklists', {})
                    cancelled = checklists.get('cancelled', {})
                    if cancelled.get('status') == 'CANCELLED':
                        items = cancelled.get('items', [])
                        for item in items:
                            if item.get('id') == 'Cancellation-reason' and item.get('selectedValue'):
                                cancelled_with_reasons += 1
                                break

            logger.info(f"\nğŸ“Š Status distribution:")
            for status, count in status_counts.items():
                logger.info(f"   {status}: {count}")

            logger.info(f"\nğŸš« Cancellation data:")
            logger.info(f"   Cancelled orders: {status_counts.get('CANCELLED', 0)}")
            logger.info(f"   With cancellation reasons: {cancelled_with_reasons}")

        success = len(all_tasks) == total
        if success:
            logger.info(f"\nğŸ‰ Successfully fetched all {total} tasks from {number_of_pages} pages!")
        else:
            logger.warning(f"\nâš ï¸ Expected {total} tasks but got {len(all_tasks)}")

        return success

    except Exception as e:
        logger.error(f"âŒ Error during all pages fetch test: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ“„ ALL PAGES FETCH TEST")
    print("=" * 60)

    success = test_all_pages_fetch()
    if success:
        print("\nğŸ‰ All pages fetch test completed successfully!")
        print("ğŸ“ Pagination logic working correctly.")
    else:
        print("\nâŒ All pages fetch test failed!")